{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43482305",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import unicodedata\n",
    "import matplotlib.font_manager as fm\n",
    "import japanize_matplotlib  # ←簡単に日本語を使えるようにする方法\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f56f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_folder_name = '2503-05'\n",
    "# data_folder_name = '2407-09'\n",
    "data_folder_name = '2407-09_ice'\n",
    "data_folder_path = Path('./data')\n",
    "\n",
    "select_folder_path = data_folder_path / data_folder_name\n",
    "result_folder_path = select_folder_path / '__Result__'\n",
    "result_folder_path.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0424840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_dir = [p for p in select_folder_path.iterdir()]\n",
    "data_folder_dir = data_folder_dir[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6486403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 商品名の表記統一マップ ===\n",
    "name_map = {\n",
    "    'アメリカーノ': 'AC',\n",
    "    'AC_シングル': 'AC',\n",
    "    'AC W': 'AC_W',\n",
    "    'AC_ダブル': 'AC_W',\n",
    "    'IAC_シングル': 'IAC',\n",
    "    'IAC_ダブル': 'IAC_W',\n",
    "\n",
    "    'ESP_シングル': 'ESP',\n",
    "    'ESP_ダブル': 'ESP_W',\n",
    "    'ESP W': 'ESP_W',\n",
    "    'カプチーノ': 'カプチ',\n",
    "    'キャララテ': 'キャラメルラテ',\n",
    "    'Iキャララテ': 'キャラメルラテ',\n",
    "    'エスプレッソトニック': 'ESPトニック',\n",
    "    'lデカフェラテ': 'Iデカフェラテ',\n",
    "\n",
    "    'アールグレイ': 'ET_ストレート',\n",
    "    'ET_ICE': 'IET_ストレート',\n",
    "    'IET': 'IET_ストレート',\n",
    "    'IEST': 'IET_ストレート',\n",
    "    'ET_ICE レモン': 'IET_レモン',\n",
    "    'ET_ICEミルク': 'IET_ミルク',\n",
    "    'EST': 'ET_ストレート',\n",
    "    'IST': 'IST_ストレート',\n",
    "    'ST_ILT': 'IST_レモン',\n",
    "    'ST_IMT': 'IST_ミルク',\n",
    "    'ST_IST': 'IST_ストレート',\n",
    "\n",
    "\n",
    "    'ゆず茶': 'ゆず',\n",
    "    'Iゆず茶': 'Iゆず',\n",
    "\n",
    "    'Iロイヤル': 'IRMT',\n",
    "    'ロイヤル': 'RMT',\n",
    "\n",
    "    'IGT': 'GT',\n",
    "    'IGTO': 'GTO',\n",
    "\n",
    "    '抹ラテ': '抹茶ラテ',\n",
    "    'I抹ラテ': 'I抹茶ラテ',\n",
    "\n",
    "    'バナナJ': 'バナJ',\n",
    "    'バナナジュース': 'バナJ',\n",
    "\n",
    "    'レモネードソーダ': 'レモソーダ',\n",
    "    'レモネソーダ': 'レモソーダ',\n",
    "\n",
    "    '豆乳変更': '豆乳',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da69edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(files_path):\n",
    "    for i, path in enumerate(files_path):\n",
    "        if i == 0:\n",
    "            df = pd.read_csv(path, usecols=[0, 1, 2, 9], encoding=\"shift-jis\")\n",
    "        else:\n",
    "            df = pd.concat([df, pd.read_csv(path, usecols=[0, 1, 2, 9], encoding=\"shift-jis\")])\n",
    "\n",
    "    return  df\n",
    "\n",
    "\n",
    "\n",
    "def normalization(df):\n",
    "\n",
    "    df['商品名'] = df['商品名'].apply(lambda x: unicodedata.normalize('NFKC', str(x)) if pd.notna(x) else x)\n",
    "\n",
    "    # === 商品名が「☆」のみの場合は種別1を商品名に移す ===\n",
    "    mask = df['商品名'].astype(str).str.strip() == '☆'\n",
    "    df.loc[mask & df['種別1'].notna(), '商品名'] = df.loc[mask & df['種別1'].notna(), '種別1']\n",
    "    df.loc[mask, '種別1'] = np.nan\n",
    "\n",
    "    # === 商品名の先頭にある \"ICE\" \"I \" を \"I\" に変換 ===\n",
    "    df['商品名'] = df['商品名'].astype(str).str.replace(r'^ICE+', 'I', regex=True)\n",
    "    df['商品名'] = df['商品名'].astype(str).str.replace(r'^I +', 'I', regex=True)\n",
    "\n",
    "    # === 商品名の先頭にある \"HOT\" \"H\" を削除 ===\n",
    "    df['商品名'] = df['商品名'].astype(str).str.replace(r'^HOT+', '', regex=True)\n",
    "    df['商品名'] = df['商品名'].astype(str).str.replace(r'^H+', '', regex=True)\n",
    "\n",
    "\n",
    "    # 不要な商品名のパターンを除外\n",
    "    words = ['カレー', 'タコ', 'クラム', 'ハーフ', 'トースト']\n",
    "    pattern = '|'.join(words)\n",
    "    df = df[~df['商品名'].astype(str).str.contains(pattern, na=False)].copy()\n",
    "\n",
    "    # 種別1の特定ワードを削除\n",
    "    words = ['食事と共', '食後', ]\n",
    "    pattern = '|'.join(words)\n",
    "    if '種別1' in df.columns:\n",
    "        mask = df['種別1'].notna()\n",
    "        df['種別1'] = df['種別1'].astype(object)\n",
    "        df.loc[mask, '種別1'] = df.loc[mask, '種別1'].astype(str).str.replace(pattern, '', regex=True)\n",
    "\n",
    "    type_cols = ['種別1', '種別2']\n",
    "    for col in type_cols:\n",
    "        if col in df.columns:\n",
    "            # === ICE ===\n",
    "            ice_mask = df[col].astype(str).str.upper().isin(['ICE', 'I'])\n",
    "            df.loc[ice_mask, '商品名'] = 'I' + df.loc[ice_mask, '商品名'].astype(str)\n",
    "            df.loc[ice_mask, col] = np.nan\n",
    "\n",
    "            # === HOT ===\n",
    "            hot_mask = df[col].astype(str).str.upper().isin(['HOT', 'H'])\n",
    "            df.loc[hot_mask, col] = np.nan\n",
    "\n",
    "            # === 「◯◯あり／なし／有り／無し」パターンの削除 ===\n",
    "            delete_pattern = r'.*(?:あり|なし|有り|無し|少なめ)$'\n",
    "            delete_mask = df[col].astype(str).str.contains(delete_pattern, na=False)\n",
    "            df.loc[delete_mask, col] = np.nan\n",
    "\n",
    "\n",
    "    # === ICの表記統一 ===\n",
    "    df['商品名'] = df['商品名'].replace('IBC', 'IC')\n",
    "\n",
    "\n",
    "    # === 紅茶（ET系 / ST系）の組み合わせパターン変換 ===\n",
    "    tea_map = {\n",
    "        ('ET', 'ET'):  'ET_ストレート',\n",
    "        ('ET', None):  'ET_ストレート',\n",
    "        ('ET', 'ELT'): 'ET_レモン',\n",
    "        ('ET', 'EMT'): 'ET_ミルク',\n",
    "        ('ST', 'ST'):  'ST_ストレート',\n",
    "        ('ST', None):  'ST_ストレート',\n",
    "        ('ST', 'LT'):  'ST_レモン',\n",
    "        ('ST', 'MT'):  'ST_ミルク',\n",
    "        ('HOT アールグレイ', None): 'ET_ストレート',\n",
    "        ('HOT アメリカーノ', None): 'AC',\n",
    "    }\n",
    "\n",
    "    for (base_name, subtype), new_name in tea_map.items():\n",
    "        if subtype is None:\n",
    "            mask = (df['商品名'] == base_name) & (df['種別1'].isna())\n",
    "        else:\n",
    "            mask = (df['商品名'] == base_name) & (df['種別1'] == subtype)\n",
    "        df.loc[mask, '商品名'] = new_name\n",
    "        df.loc[mask, ['種別1', '種別2']] = np.nan\n",
    "\n",
    "\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def preprocessing(row):\n",
    "    parts = []\n",
    "\n",
    "    # 商品名（NaN でないもののみ）\n",
    "    if pd.notna(row['商品名']):\n",
    "        parts.append(str(row['商品名']).replace('☆', '').strip())\n",
    "\n",
    "    # 種別1（NaNでも空文字でもないもの）\n",
    "    if '種別1' in row and pd.notna(row['種別1']) and row['種別1'].strip() and row['種別1'] != row['商品名']:\n",
    "        parts.append(row['種別1'].strip())\n",
    "\n",
    "    # 種別2（NaNでも空文字でもないもの）\n",
    "    if '種別2' in row and pd.notna(row['種別2']) and row['種別2'].strip():\n",
    "        parts.append(row['種別2'].strip())\n",
    "\n",
    "    return '_'.join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebd1a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1フォルダのみに使用（デバッグ用）\n",
    "files = [q for q in data_folder_dir[0].iterdir()]\n",
    "\n",
    "df = load_csv(files)\n",
    "\n",
    "df = normalization(df)\n",
    "\n",
    "df['商品名'] = df.apply(preprocessing, axis=1)\n",
    "\n",
    "\n",
    "if '種別1' in df.columns:\n",
    "    df.drop(columns=['種別1'], inplace=True)\n",
    "if '種別2' in df.columns:\n",
    "    df.drop(columns=['種別2'], inplace=True)\n",
    "\n",
    "# 商品名の正規化（前処理済みの状態に対してマップ）\n",
    "df['商品名'] = df['商品名'].replace(name_map)\n",
    "\n",
    "all_df = df\n",
    "\n",
    "df_summary = all_df.groupby('商品名', as_index=False).sum()\n",
    "\n",
    "# df_summary.to_csv(data_folder_dir[1]/'df_summary.csv',index= False, encoding=\"shift_jis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486747e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3400c043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataフォルダ内の全フォルダに適用（本命）\n",
    "\n",
    "for j, dir_path in enumerate(data_folder_dir):\n",
    "    files = [q for q in dir_path.iterdir()]\n",
    "    \n",
    "    df = load_csv(files)\n",
    "\n",
    "    df = normalization(df)\n",
    "\n",
    "    df['商品名'] = df.apply(preprocessing, axis=1)\n",
    "\n",
    "    if '種別1' in df.columns:\n",
    "        df.drop(columns=['種別1'], inplace=True)\n",
    "    if '種別2' in df.columns:\n",
    "        df.drop(columns=['種別2'], inplace=True)\n",
    "\n",
    "    # 商品名の正規化（前処理済みの状態に対してマップ）\n",
    "    df['商品名'] = df['商品名'].replace(name_map)\n",
    "\n",
    "    df.to_csv(result_folder_path/f'{dir_path.name}.csv',index= False, encoding=\"shift_jis\")\n",
    "\n",
    "    if j == 0:\n",
    "        all_df = df\n",
    "    else:\n",
    "        all_df = pd.concat([all_df, df], ignore_index=True)\n",
    "\n",
    "df_summary = all_df.groupby('商品名', as_index=False).sum()\n",
    "df_summary.to_csv(result_folder_path/f'__{data_folder_name}_df_summary.csv',index= False, encoding=\"shift_jis\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d89ff21",
   "metadata": {},
   "source": [
    "## 注文数上位10件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86f0882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib  # 日本語表示対応\n",
    "\n",
    "# 上位15商品の取得（販売商品数順）\n",
    "top15 = df_summary.sort_values('販売商品数', ascending=False).head(10)\n",
    "# top15 = df_summary.sort_values('販売商品数', ascending=False)\n",
    "\n",
    "# %と個数を同時に表示する関数\n",
    "def make_autopct(values):\n",
    "    def my_autopct(pct):\n",
    "        total = sum(values)\n",
    "        val = int(round(pct * total / 100.0))\n",
    "        return f'{val}個\\n({pct:.1f}%)'\n",
    "    return my_autopct\n",
    "\n",
    "# 円グラフの描画\n",
    "fig, ax = plt.subplots(figsize=(9, 8))\n",
    "wedges, texts, autotexts = ax.pie(\n",
    "    top15['販売商品数'],\n",
    "    autopct=make_autopct(top15['販売商品数']),\n",
    "    startangle=140\n",
    ")\n",
    "\n",
    "# 凡例の追加\n",
    "ax.legend(wedges, top15['商品名'], title=\"商品名\", loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# タイトルとレイアウト調整\n",
    "plt.title(f'{data_folder_name}_販売数 上位10商品')\n",
    "plt.tight_layout()\n",
    "plt.savefig(result_folder_path/f'__{data_folder_name}_pie_graph.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbe3b81",
   "metadata": {},
   "source": [
    "## コーヒー類のみ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28588ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee = {\n",
    "    'BC': 'BC',\n",
    "    'IC': 'BC',\n",
    "    'ダーク': 'ダーク',\n",
    "    'Iダーク': 'ダーク',\n",
    "    'マンデ': 'マンデ',\n",
    "    'Iマンデ': 'マンデ',\n",
    "    'モカ': 'モカ',\n",
    "    'Iモカ': 'モカ',\n",
    "    'ブラジル': 'ブラジル',\n",
    "    'Iブラジル': 'ブラジル',\n",
    "    'デカフェ': 'デカフェ',\n",
    "    'Iデカフェ': 'デカフェ',\n",
    "    }\n",
    "\n",
    "df_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b0adf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coffeeに含まれる商品名のみ抽出\n",
    "coffee_keys = list(coffee.keys())\n",
    "coffee_df = df_summary[df_summary['商品名'].isin(coffee_keys)].copy()\n",
    "coffee_df\n",
    "\n",
    "# 販売数の多い順に上位10商品を取得\n",
    "top10_coffee = coffee_df.sort_values('販売商品数', ascending=False).head(10)\n",
    "\n",
    "# 上位10商品の合計販売数を計算\n",
    "total = top10_coffee['販売商品数'].sum()\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# 各セクションの合計値と割合を含むラベルを作成\n",
    "labels = [\n",
    "    f\"{row['商品名']}: {row['販売商品数']}個 ({row['販売商品数'] / top10_coffee['販売商品数'].sum():.1%})\"\n",
    "    for _, row in top10_coffee.iterrows()\n",
    "]\n",
    "\n",
    "# 円グラフを描画\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# 円グラフ描画\n",
    "wedges, texts, autotexts = ax.pie(\n",
    "    top10_coffee['販売商品数'],\n",
    "    labels=labels,\n",
    "    startangle=90,\n",
    "    autopct=lambda pct: '',  # 中央テキストを後で手動設定\n",
    "    textprops=dict(color=\"white\", fontsize=9)\n",
    ")\n",
    "\n",
    "# 上位3位は中央に商品名＋個数＋割合を表示\n",
    "for i, autotext in enumerate(autotexts):\n",
    "    if i < 3:\n",
    "        pct = top10_coffee.iloc[i]['販売商品数'] / total * 100\n",
    "        val = top10_coffee.iloc[i]['販売商品数']\n",
    "        autotext.set_text(f\"{top10_coffee.iloc[i]['商品名']}\\n{val}個\\n({pct:.1f}%)\")\n",
    "    else:\n",
    "        autotext.set_text('')\n",
    "\n",
    "# 凡例に情報を表示\n",
    "plt.legend(wedges, labels, title=\"商品名\", loc=\"center left\", bbox_to_anchor=(1.0, 0.5))\n",
    "\n",
    "plt.title(f'{data_folder_name}_コーヒー系（ICE/HOT別）販売上位10商品')\n",
    "plt.tight_layout()\n",
    "plt.savefig(result_folder_path/f'__{data_folder_name}_coffee_top10.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8a4ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coffee に含まれるキーワードが商品名に含まれているデータのみ抽出\n",
    "def find_coffee_base(name):\n",
    "    for key in coffee.keys():\n",
    "        if key in name:\n",
    "            return coffee[key]\n",
    "    return None\n",
    "\n",
    "# ベースカテゴリ列を追加\n",
    "df_summary['coffee_base'] = df_summary['商品名'].apply(find_coffee_base)\n",
    "\n",
    "# コーヒー系のみ抽出し、ベース名で集計\n",
    "coffee_df_merged = df_summary[df_summary['coffee_base'].notna()].copy()\n",
    "coffee_agg = coffee_df_merged.groupby('coffee_base', as_index=False)['販売商品数'].sum()\n",
    "\n",
    "# 販売数の多い順に上位10商品を取得\n",
    "top10_coffee = coffee_agg.sort_values('販売商品数', ascending=False).head(10)\n",
    "\n",
    "# 合計販売数\n",
    "total = top10_coffee['販売商品数'].sum()\n",
    "\n",
    "# 描画開始\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# ラベル作成（凡例用）\n",
    "labels = [\n",
    "    f\"{row['coffee_base']}: {row['販売商品数']}個 ({row['販売商品数'] / total:.1%})\"\n",
    "    for _, row in top10_coffee.iterrows()\n",
    "]\n",
    "\n",
    "# 円グラフ\n",
    "wedges, texts, autotexts = ax.pie(\n",
    "    top10_coffee['販売商品数'],\n",
    "    labels=None,\n",
    "    startangle=90,\n",
    "    autopct=lambda pct: '',\n",
    "    textprops=dict(color=\"white\", fontsize=9)\n",
    ")\n",
    "\n",
    "# 上位3位に中央にテキスト表示\n",
    "for i, autotext in enumerate(autotexts):\n",
    "    if i < 3:\n",
    "        pct = top10_coffee.iloc[i]['販売商品数'] / total * 100\n",
    "        val = top10_coffee.iloc[i]['販売商品数']\n",
    "        name = top10_coffee.iloc[i]['coffee_base']\n",
    "        autotext.set_text(f\"{name}\\n{val}個\\n({pct:.1f}%)\")\n",
    "    else:\n",
    "        autotext.set_text('')\n",
    "\n",
    "# 凡例\n",
    "ax.legend(\n",
    "    wedges,\n",
    "    labels,\n",
    "    title=\"商品名\",\n",
    "    loc=\"center left\",\n",
    "    bbox_to_anchor=(1.0, 0.5),\n",
    "    fontsize=10\n",
    ")\n",
    "\n",
    "ax.set_title(f'{data_folder_name}_コーヒー系（ICE/HOT統合）販売数')\n",
    "plt.tight_layout()\n",
    "plt.savefig(result_folder_path/f'__{data_folder_name}_coffee_top10_merged.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2381c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zemi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
